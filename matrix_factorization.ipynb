{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_items = pd.read_csv('/Users/vince/Salk/mCC_Analysis/data/compliant_user_items.csv')\n",
    "\n",
    "# Load JSON file containing food corrections\n",
    "with open('/Users/vince/Salk/mCC_Analysis/food_corrections.json', 'r') as f:\n",
    "    food_corrections = json.load(f)\n",
    "\n",
    "# Create a new column with corrected food names\n",
    "user_items['corrected_food'] = user_items['parsing_result'].map(food_corrections)\n",
    "user_items['corrected_food'] = user_items['corrected_food'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>food_item</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nespresso</td>\n",
       "      <td>[-0.0067176544, -0.02788784, -0.012478107, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>oatmeal</td>\n",
       "      <td>[0.02143874, 0.021305107, 0.022809047, -0.0474...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>milk</td>\n",
       "      <td>[0.034871925, 0.0069323634, -0.035317637, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>eggplant</td>\n",
       "      <td>[-0.0074746986, -0.072444454, -0.004489695, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lasagna</td>\n",
       "      <td>[0.020851888, -0.050679404, 0.03552969, 0.0090...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2658</th>\n",
       "      <td>asahi vegan beer</td>\n",
       "      <td>[0.005335356, 0.0065996544, -0.025653338, 0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2659</th>\n",
       "      <td>eye of round roast</td>\n",
       "      <td>[0.0687832, -0.020699274, 0.03731008, -0.00327...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2660</th>\n",
       "      <td>whey hydrolysate isolate zero</td>\n",
       "      <td>[0.042257965, -0.020719532, -0.069381446, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2661</th>\n",
       "      <td>barukas</td>\n",
       "      <td>[-0.0714513, 0.007650819, 0.023063982, -0.0228...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2662</th>\n",
       "      <td>chocolate cacao husk tea</td>\n",
       "      <td>[-0.018887958, -0.026476186, -0.060771924, -0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2663 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          food_item  \\\n",
       "0                         nespresso   \n",
       "1                           oatmeal   \n",
       "2                              milk   \n",
       "3                          eggplant   \n",
       "4                           lasagna   \n",
       "...                             ...   \n",
       "2658               asahi vegan beer   \n",
       "2659             eye of round roast   \n",
       "2660  whey hydrolysate isolate zero   \n",
       "2661                        barukas   \n",
       "2662       chocolate cacao husk tea   \n",
       "\n",
       "                                              embedding  \n",
       "0     [-0.0067176544, -0.02788784, -0.012478107, 0.0...  \n",
       "1     [0.02143874, 0.021305107, 0.022809047, -0.0474...  \n",
       "2     [0.034871925, 0.0069323634, -0.035317637, -0.0...  \n",
       "3     [-0.0074746986, -0.072444454, -0.004489695, 0....  \n",
       "4     [0.020851888, -0.050679404, 0.03552969, 0.0090...  \n",
       "...                                                 ...  \n",
       "2658  [0.005335356, 0.0065996544, -0.025653338, 0.00...  \n",
       "2659  [0.0687832, -0.020699274, 0.03731008, -0.00327...  \n",
       "2660  [0.042257965, -0.020719532, -0.069381446, -0.0...  \n",
       "2661  [-0.0714513, 0.007650819, 0.023063982, -0.0228...  \n",
       "2662  [-0.018887958, -0.026476186, -0.060771924, -0....  \n",
       "\n",
       "[2663 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle \n",
    "\n",
    "with open('food_embeddings.pkl', 'rb') as f:\n",
    "    food_embeddings = pickle.load(f)\n",
    "\n",
    "food_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_items['embedding'] = user_items['corrected_food'].map(food_embeddings.set_index('food_item')['embedding'].to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pid</th>\n",
       "      <th>compliance_days_passed</th>\n",
       "      <th>food_type</th>\n",
       "      <th>original_logtime</th>\n",
       "      <th>log_date</th>\n",
       "      <th>time</th>\n",
       "      <th>compliance_date</th>\n",
       "      <th>parsing_result</th>\n",
       "      <th>corrected_food</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alqt150211047</td>\n",
       "      <td>0</td>\n",
       "      <td>b</td>\n",
       "      <td>2021-10-28 09:45:59</td>\n",
       "      <td>2021-10-28</td>\n",
       "      <td>9.766389</td>\n",
       "      <td>2021-10-28</td>\n",
       "      <td>nespresso</td>\n",
       "      <td>nespresso</td>\n",
       "      <td>[-0.0067176544, -0.02788784, -0.012478107, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alqt150211047</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>2021-10-28 09:45:59</td>\n",
       "      <td>2021-10-28</td>\n",
       "      <td>9.766389</td>\n",
       "      <td>2021-10-28</td>\n",
       "      <td>oatmeal</td>\n",
       "      <td>oatmeal</td>\n",
       "      <td>[0.02143874, 0.021305107, 0.022809047, -0.0474...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>alqt150211047</td>\n",
       "      <td>0</td>\n",
       "      <td>b</td>\n",
       "      <td>2021-10-28 09:45:59</td>\n",
       "      <td>2021-10-28</td>\n",
       "      <td>9.766389</td>\n",
       "      <td>2021-10-28</td>\n",
       "      <td>milk</td>\n",
       "      <td>milk</td>\n",
       "      <td>[0.034871925, 0.0069323634, -0.035317637, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>alqt150211047</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>2021-10-28 11:57:00</td>\n",
       "      <td>2021-10-28</td>\n",
       "      <td>11.950000</td>\n",
       "      <td>2021-10-28</td>\n",
       "      <td>eggplant</td>\n",
       "      <td>eggplant</td>\n",
       "      <td>[-0.0074746986, -0.072444454, -0.004489695, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>alqt150211047</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>2021-10-28 11:57:00</td>\n",
       "      <td>2021-10-28</td>\n",
       "      <td>11.950000</td>\n",
       "      <td>2021-10-28</td>\n",
       "      <td>lasagna</td>\n",
       "      <td>lasagna</td>\n",
       "      <td>[0.020851888, -0.050679404, 0.03552969, 0.0090...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3184274</th>\n",
       "      <td>alqt230941256543</td>\n",
       "      <td>13</td>\n",
       "      <td>b</td>\n",
       "      <td>2023-09-21 16:32:00</td>\n",
       "      <td>2023-09-21</td>\n",
       "      <td>16.533333</td>\n",
       "      <td>2023-09-21</td>\n",
       "      <td>hibiscus tea</td>\n",
       "      <td>hibiscus tea</td>\n",
       "      <td>[0.020282893, -0.030562764, -0.028167933, 0.01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3184275</th>\n",
       "      <td>alqt230941256543</td>\n",
       "      <td>13</td>\n",
       "      <td>f</td>\n",
       "      <td>2023-09-21 16:32:00</td>\n",
       "      <td>2023-09-21</td>\n",
       "      <td>16.533333</td>\n",
       "      <td>2023-09-21</td>\n",
       "      <td>blueberry</td>\n",
       "      <td>blueberry</td>\n",
       "      <td>[0.015543392, -0.052315928, 0.0055276155, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3184276</th>\n",
       "      <td>alqt230941256543</td>\n",
       "      <td>13</td>\n",
       "      <td>f</td>\n",
       "      <td>2023-09-21 19:25:00</td>\n",
       "      <td>2023-09-21</td>\n",
       "      <td>19.416667</td>\n",
       "      <td>2023-09-21</td>\n",
       "      <td>baked chicken</td>\n",
       "      <td>baked chicken</td>\n",
       "      <td>[-0.0056958185, -0.014435805, 0.038879912, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3184277</th>\n",
       "      <td>alqt230941256543</td>\n",
       "      <td>13</td>\n",
       "      <td>f</td>\n",
       "      <td>2023-09-21 19:25:00</td>\n",
       "      <td>2023-09-21</td>\n",
       "      <td>19.416667</td>\n",
       "      <td>2023-09-21</td>\n",
       "      <td>mashed potato</td>\n",
       "      <td>mashed potato</td>\n",
       "      <td>[-0.0072039505, -0.0070065106, -0.008313367, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3184278</th>\n",
       "      <td>alqt230941256543</td>\n",
       "      <td>13</td>\n",
       "      <td>f</td>\n",
       "      <td>2023-09-21 19:25:00</td>\n",
       "      <td>2023-09-21</td>\n",
       "      <td>19.416667</td>\n",
       "      <td>2023-09-21</td>\n",
       "      <td>salad</td>\n",
       "      <td>salad</td>\n",
       "      <td>[-0.005880775, -0.025119923, 0.032096796, -0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3184279 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      pid  compliance_days_passed food_type  \\\n",
       "0           alqt150211047                       0         b   \n",
       "1           alqt150211047                       0         f   \n",
       "2           alqt150211047                       0         b   \n",
       "3           alqt150211047                       0         f   \n",
       "4           alqt150211047                       0         f   \n",
       "...                   ...                     ...       ...   \n",
       "3184274  alqt230941256543                      13         b   \n",
       "3184275  alqt230941256543                      13         f   \n",
       "3184276  alqt230941256543                      13         f   \n",
       "3184277  alqt230941256543                      13         f   \n",
       "3184278  alqt230941256543                      13         f   \n",
       "\n",
       "            original_logtime    log_date       time compliance_date  \\\n",
       "0        2021-10-28 09:45:59  2021-10-28   9.766389      2021-10-28   \n",
       "1        2021-10-28 09:45:59  2021-10-28   9.766389      2021-10-28   \n",
       "2        2021-10-28 09:45:59  2021-10-28   9.766389      2021-10-28   \n",
       "3        2021-10-28 11:57:00  2021-10-28  11.950000      2021-10-28   \n",
       "4        2021-10-28 11:57:00  2021-10-28  11.950000      2021-10-28   \n",
       "...                      ...         ...        ...             ...   \n",
       "3184274  2023-09-21 16:32:00  2023-09-21  16.533333      2023-09-21   \n",
       "3184275  2023-09-21 16:32:00  2023-09-21  16.533333      2023-09-21   \n",
       "3184276  2023-09-21 19:25:00  2023-09-21  19.416667      2023-09-21   \n",
       "3184277  2023-09-21 19:25:00  2023-09-21  19.416667      2023-09-21   \n",
       "3184278  2023-09-21 19:25:00  2023-09-21  19.416667      2023-09-21   \n",
       "\n",
       "        parsing_result corrected_food  \\\n",
       "0            nespresso      nespresso   \n",
       "1              oatmeal        oatmeal   \n",
       "2                 milk           milk   \n",
       "3             eggplant       eggplant   \n",
       "4              lasagna        lasagna   \n",
       "...                ...            ...   \n",
       "3184274   hibiscus tea   hibiscus tea   \n",
       "3184275      blueberry      blueberry   \n",
       "3184276  baked chicken  baked chicken   \n",
       "3184277  mashed potato  mashed potato   \n",
       "3184278          salad          salad   \n",
       "\n",
       "                                                 embedding  \n",
       "0        [-0.0067176544, -0.02788784, -0.012478107, 0.0...  \n",
       "1        [0.02143874, 0.021305107, 0.022809047, -0.0474...  \n",
       "2        [0.034871925, 0.0069323634, -0.035317637, -0.0...  \n",
       "3        [-0.0074746986, -0.072444454, -0.004489695, 0....  \n",
       "4        [0.020851888, -0.050679404, 0.03552969, 0.0090...  \n",
       "...                                                    ...  \n",
       "3184274  [0.020282893, -0.030562764, -0.028167933, 0.01...  \n",
       "3184275  [0.015543392, -0.052315928, 0.0055276155, -0.0...  \n",
       "3184276  [-0.0056958185, -0.014435805, 0.038879912, -0....  \n",
       "3184277  [-0.0072039505, -0.0070065106, -0.008313367, -...  \n",
       "3184278  [-0.005880775, -0.025119923, 0.032096796, -0.0...  \n",
       "\n",
       "[3184279 rows x 10 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_sleep = pd.read_csv('/Users/vince/Salk/mCC_Analysis/data/compliant_user_sleep.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'user_sleep' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43muser_sleep\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124menough_sleep\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalue_counts()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'user_sleep' is not defined"
     ]
    }
   ],
   "source": [
    "user_sleep['enough_sleep'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrix Factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix will have 20201 users and 2661 food items\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from typing import Tuple, List, Dict\n",
    "\n",
    "def prepare_user_food_matrix(user_items_df):\n",
    "    \"\"\"\n",
    "    Create a user-food matrix with frequency counts.\n",
    "    \n",
    "    Assumptions:\n",
    "    - Each food item is treated as a distinct category\n",
    "    - The value in the matrix represents how many times a user consumed that food\n",
    "    - No semantic similarity between foods is considered at this stage\n",
    "    \"\"\"\n",
    "    # Select relevant columns\n",
    "    df = user_items_df[['pid', 'corrected_food']]\n",
    "    \n",
    "    # Get unique users and foods\n",
    "    users = df['pid'].unique().tolist()\n",
    "    foods = df['corrected_food'].unique().tolist()\n",
    "    \n",
    "    print(f\"Matrix will have {len(users)} users and {len(foods)} food items\")\n",
    "    \n",
    "    # Create mappings\n",
    "    user_map = {user: i for i, user in enumerate(users)}\n",
    "    food_map = {food: i for i, food in enumerate(foods)}\n",
    "    \n",
    "    # Create matrix coordinates\n",
    "    rows = df['pid'].map(user_map).values\n",
    "    cols = df['corrected_food'].map(food_map).values\n",
    "    values = np.ones(len(df))  # Count occurrences\n",
    "    \n",
    "    # Create a sparse matrix\n",
    "    from scipy.sparse import csr_matrix\n",
    "    user_food_matrix = csr_matrix((values, (rows, cols)), \n",
    "                                 shape=(len(users), len(foods)))\n",
    "    \n",
    "    return user_food_matrix, users, foods\n",
    " \n",
    "# Intersection of users\n",
    "food_users = user_items['pid'].unique()\n",
    "sleep_users = user_sleep['pid'].unique()\n",
    "\n",
    "intersection = set(food_users).intersection(set(sleep_users))\n",
    "\n",
    "user_items_df = user_items[user_items['pid'].isin(intersection)]\n",
    "\n",
    "user_food_matrix, users, foods = prepare_user_food_matrix(user_items_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying NMF with 20 components\n",
      "User factors shape: (20201, 20)\n",
      "Food factors shape: (20, 2661)\n"
     ]
    }
   ],
   "source": [
    "def apply_matrix_factorization(matrix, n_components=20):\n",
    "    \"\"\"\n",
    "    Apply Non-Negative Matrix Factorization to extract latent factors.\n",
    "    \n",
    "    Assumptions:\n",
    "    - The number of components (n_components) represents underlying patterns\n",
    "    - Non-negativity constraint makes sense for food consumption data\n",
    "    - These latent factors will represent patterns like \"breakfast foods\", \"protein foods\", etc.\n",
    "    \"\"\"\n",
    "    from sklearn.decomposition import NMF\n",
    "    \n",
    "    print(f\"Applying NMF with {n_components} components\")\n",
    "    model = NMF(\n",
    "        n_components=n_components,\n",
    "        init='random',\n",
    "        random_state=42,\n",
    "        max_iter=200\n",
    "    )\n",
    "    \n",
    "    user_factors = model.fit_transform(matrix)\n",
    "    food_factors = model.components_\n",
    "    \n",
    "    print(f\"User factors shape: {user_factors.shape}\")\n",
    "    print(f\"Food factors shape: {food_factors.shape}\")\n",
    "    \n",
    "    return user_factors, food_factors, model\n",
    "\n",
    "user_factors, food_factors, model = apply_matrix_factorization(user_food_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dv/lndb9rrs2kv2v5g8cyfyx0wr0000gn/T/ipykernel_61960/1212470673.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['time_bin'] = pd.cut(df['time'], bins=time_bins, labels=bin_labels)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temporal features created for 20201 users\n"
     ]
    }
   ],
   "source": [
    "def extract_temporal_features(user_items_df):\n",
    "    \"\"\"\n",
    "    Extract features about when users eat.\n",
    "    \n",
    "    Assumptions:\n",
    "    - Time of day is divided into 4 bins (night, morning, afternoon, evening)\n",
    "    - The percentage of meals in each time bin is a meaningful feature\n",
    "    - Variance in eating times represents regularity/irregularity\n",
    "    - Average time between meals captures eating frequency\n",
    "    \"\"\"\n",
    "    # Select relevant columns\n",
    "    df = user_items_df[['pid', 'time']]\n",
    "    \n",
    "    # Create time bins\n",
    "    time_bins = [0, 6, 12, 18, 24]\n",
    "    bin_labels = ['night', 'morning', 'afternoon', 'evening']\n",
    "    df['time_bin'] = pd.cut(df['time'], bins=time_bins, labels=bin_labels)\n",
    "    \n",
    "    # Get unique users\n",
    "    users = df['pid'].unique().tolist()\n",
    "    \n",
    "    # Initialize features DataFrame\n",
    "    temporal_features = pd.DataFrame({'pid': users})\n",
    "    \n",
    "    # Calculate percentage of meals in each time bin\n",
    "    for bin_label in bin_labels:\n",
    "        bin_counts = df[df['time_bin'] == bin_label].groupby('pid').size()\n",
    "        bin_counts = bin_counts.reindex(users).fillna(0)\n",
    "        \n",
    "        total_counts = df.groupby('pid').size()\n",
    "        total_counts = total_counts.reindex(users).fillna(1)  # Avoid division by zero\n",
    "        \n",
    "        percentage = (bin_counts / total_counts * 100).values\n",
    "        temporal_features[f'pct_{bin_label}_meals'] = percentage\n",
    "    \n",
    "    # Calculate variance in eating times\n",
    "    time_variance = df.groupby('pid')['time'].var().reindex(users).fillna(0)\n",
    "    temporal_features['time_variance'] = time_variance.values\n",
    "    \n",
    "    # Calculate average time between meals per day\n",
    "    df_sorted = df.sort_values(['pid', 'time'])\n",
    "    df_sorted['time_diff'] = df_sorted.groupby('pid')['time'].diff()\n",
    "    avg_time_diff = df_sorted.groupby('pid')['time_diff'].mean().reindex(users).fillna(0)\n",
    "    temporal_features['avg_time_between_meals'] = avg_time_diff.values\n",
    "    \n",
    "    print(f\"Temporal features created for {len(users)} users\")\n",
    "    return temporal_features, users\n",
    "\n",
    "temporal_features, users = extract_temporal_features(user_items_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sleep features created for 20201 users\n"
     ]
    }
   ],
   "source": [
    "def prepare_sleep_features(user_sleep_df):\n",
    "    \"\"\"\n",
    "    Aggregate sleep data into user features.\n",
    "    \n",
    "    Assumptions:\n",
    "    - Mean and standard deviation capture sleep patterns\n",
    "    - Users with consistent sleep patterns will have low standard deviation\n",
    "    - Missing values (e.g., for users with only one record) are filled with 0\n",
    "    \"\"\"\n",
    "    # Select relevant columns\n",
    "    df = user_sleep_df[['pid', 'sleep_time_decimal', 'sleep_duration_decimal', 'wakeup_time_decimal']]\n",
    "    \n",
    "    # Group by user and aggregate\n",
    "    sleep_features = df.groupby('pid').agg({\n",
    "        'sleep_time_decimal': ['mean', 'std'],\n",
    "        'sleep_duration_decimal': ['mean', 'std'],\n",
    "        'wakeup_time_decimal': ['mean', 'std']\n",
    "    }).reset_index()\n",
    "    \n",
    "    # Flatten column names\n",
    "    sleep_features.columns = ['pid'] + [\n",
    "        f'{col[0]}_{col[1]}' for col in sleep_features.columns[1:]\n",
    "    ]\n",
    "    \n",
    "    # Handle missing values\n",
    "    sleep_features = sleep_features.fillna(0)\n",
    "    \n",
    "    users = sleep_features['pid'].tolist()\n",
    "    print(f\"Sleep features created for {len(users)} users\")\n",
    "    \n",
    "    return sleep_features, users\n",
    "\n",
    "sleep_features, users = prepare_sleep_features(user_sleep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users with food factors: 20201\n",
      "Users with temporal features: 20201\n",
      "Users with sleep features: 20201\n",
      "Combining features...\n",
      "After merging temporal: 20201 users\n",
      "After merging sleep: 20201 users\n",
      "Combined features for 20201 users with 32 features each\n"
     ]
    }
   ],
   "source": [
    "def combine_features(user_factors, users_mf, temporal_features, sleep_features):\n",
    "    \"\"\"\n",
    "    Combine all feature sets into a unified representation.\n",
    "    \"\"\"\n",
    "    # Convert user factors to DataFrame\n",
    "    user_factors_df = pd.DataFrame(\n",
    "        user_factors, \n",
    "        columns=[f'factor_{i}' for i in range(user_factors.shape[1])]\n",
    "    )\n",
    "    user_factors_df['pid'] = users_mf  # This line is causing the error\n",
    "    \n",
    "    # Ensure users match between dataframes\n",
    "    print(f\"Users with food factors: {len(users_mf)}\")\n",
    "    print(f\"Users with temporal features: {temporal_features['pid'].nunique()}\")\n",
    "    print(f\"Users with sleep features: {sleep_features['pid'].nunique()}\")\n",
    "    \n",
    "    # Merge with temporal features\n",
    "    print(\"Combining features...\")\n",
    "    combined_df = user_factors_df.merge(temporal_features, on='pid', how='inner')\n",
    "    print(f\"After merging temporal: {combined_df.shape[0]} users\")\n",
    "    \n",
    "    # Merge with sleep features\n",
    "    combined_df = combined_df.merge(sleep_features, on='pid', how='inner')\n",
    "    print(f\"After merging sleep: {combined_df.shape[0]} users\")\n",
    "    \n",
    "    print(f\"Combined features for {combined_df.shape[0]} users with {combined_df.shape[1]-1} features each\")\n",
    "    \n",
    "    return combined_df\n",
    "\n",
    "combined_df = combine_features(user_factors, users, temporal_features, sleep_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering into 5 clusters...\n",
      "Silhouette score: 0.0442\n"
     ]
    }
   ],
   "source": [
    "def cluster_users(combined_df, n_clusters=5):\n",
    "    \"\"\"\n",
    "    Cluster users based on combined features.\n",
    "    \n",
    "    Assumptions:\n",
    "    - Features should be standardized before clustering\n",
    "    - K-means is an appropriate algorithm for this data\n",
    "    - The specified number of clusters will yield meaningful patterns\n",
    "    - Silhouette score is a good metric for cluster quality\n",
    "    \"\"\"\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.cluster import KMeans\n",
    "    from sklearn.metrics import silhouette_score\n",
    "    \n",
    "    # Extract features (exclude pid)\n",
    "    features = combined_df.drop('pid', axis=1).values\n",
    "    \n",
    "    # Standardize features\n",
    "    scaler = StandardScaler()\n",
    "    features_scaled = scaler.fit_transform(features)\n",
    "    \n",
    "    # Apply K-means clustering\n",
    "    print(f\"Clustering into {n_clusters} clusters...\")\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
    "    labels = kmeans.fit_predict(features_scaled)\n",
    "    \n",
    "    # Evaluate clustering\n",
    "    score = silhouette_score(features_scaled, labels)\n",
    "    print(f\"Silhouette score: {score:.4f}\")\n",
    "    \n",
    "    return labels, score\n",
    "\n",
    "labels, score = cluster_users(combined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering into 2 clusters...\n",
      "Silhouette score: 0.0711\n",
      "Clusters: 2, Silhouette Score: 0.0711\n",
      "Clustering into 3 clusters...\n",
      "Silhouette score: 0.0586\n",
      "Clusters: 3, Silhouette Score: 0.0586\n",
      "Clustering into 4 clusters...\n",
      "Silhouette score: 0.0521\n",
      "Clusters: 4, Silhouette Score: 0.0521\n",
      "Clustering into 5 clusters...\n",
      "Silhouette score: 0.0442\n",
      "Clusters: 5, Silhouette Score: 0.0442\n",
      "Clustering into 6 clusters...\n",
      "Silhouette score: 0.0471\n",
      "Clusters: 6, Silhouette Score: 0.0471\n",
      "Clustering into 7 clusters...\n",
      "Silhouette score: 0.0487\n",
      "Clusters: 7, Silhouette Score: 0.0487\n",
      "Clustering into 8 clusters...\n",
      "Silhouette score: 0.0497\n",
      "Clusters: 8, Silhouette Score: 0.0497\n",
      "Clustering into 9 clusters...\n",
      "Silhouette score: 0.0431\n",
      "Clusters: 9, Silhouette Score: 0.0431\n",
      "Clustering into 10 clusters...\n",
      "Silhouette score: 0.0463\n",
      "Clusters: 10, Silhouette Score: 0.0463\n",
      "Optimal number of clusters: 2\n"
     ]
    }
   ],
   "source": [
    "def find_optimal_clusters(combined_df, max_clusters=10):\n",
    "    \"\"\"\n",
    "    Find optimal number of clusters using silhouette score.\n",
    "    \n",
    "    Assumptions:\n",
    "    - The optimal number of clusters is between 2 and max_clusters\n",
    "    - Silhouette score is a reliable metric for cluster quality\n",
    "    - Higher silhouette score indicates better clustering\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    for n_clusters in range(2, max_clusters + 1):\n",
    "        labels, score = cluster_users(combined_df, n_clusters=n_clusters)\n",
    "        results[n_clusters] = score\n",
    "        print(f\"Clusters: {n_clusters}, Silhouette Score: {score:.4f}\")\n",
    "    \n",
    "    optimal_clusters = max(results, key=results.get)\n",
    "    print(f\"Optimal number of clusters: {optimal_clusters}\")\n",
    "    \n",
    "    return results, optimal_clusters\n",
    "\n",
    "results, optimal_clusters = find_optimal_clusters(combined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimal_clusters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
